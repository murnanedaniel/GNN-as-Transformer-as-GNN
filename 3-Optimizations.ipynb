{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114dd605-41de-4a02-a87a-caefa628569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/gnn4na/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Don't track gradients\n",
    "# torch.set_grad_enabled(False)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1df3a1-dd88-4fe0-a14c-827acca0182c",
   "metadata": {},
   "source": [
    "## Node-to-node Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea52147-cca8-4fac-bfbe-5a86732ee391",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1b63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74b5590-402f-4455-a07e-69cfcdd4406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100000\n",
    "num_hidden = 256\n",
    "batch_size = 1\n",
    "attention_heads = 1\n",
    "h = torch.randn(batch_size, attention_heads, num_nodes, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38cc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "\n",
    "# apply linear layers to compute query, key, and value\n",
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f57456-a384-43d0-943d-1f1d7ae6804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  393.00390625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64a4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.81 ms, sys: 16 ms, total: 24.8 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute dot product of query and key, and apply softmax\n",
    "dot_product = torch.matmul(q, k.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "134d404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  38539.9765625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a940ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 ms, sys: 0 ns, total: 1.39 ms\n",
      "Wall time: 634 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# apply dot product of attention weights and value\n",
    "attn_output = torch.matmul(dot_product, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03781231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  38637.9765625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0062947f-dee4-4b98-a437-5582ac8dcd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-19410.9531, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output[0][0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51527ac0",
   "metadata": {},
   "source": [
    "## Feature-to-feature Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fb651a-6b03-47be-8034-fc4bedcd842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100000\n",
    "num_hidden = 256\n",
    "batch_size = 1\n",
    "attention_heads = 1\n",
    "h = torch.randn(batch_size, attention_heads, num_nodes, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dc26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "\n",
    "# apply linear layers to compute query, key, and value\n",
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b25759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  393.00390625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65961e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  423.771484375 MB\n",
      "Time taken:  1.656831979751587 ms\n",
      "CPU times: user 2.53 ms, sys: 0 ns, total: 2.53 ms\n",
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "# compute dot product of query and key, and apply softmax\n",
    "dot_product = torch.matmul(k.transpose(2, 3), v)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  589.25390625 MB\n",
      "Time taken:  1.7776639461517334 ms\n",
      "CPU times: user 2.69 ms, sys: 0 ns, total: 2.69 ms\n",
      "Wall time: 2.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "# apply dot product of attention weights and value\n",
    "attn_output = torch.matmul(q, dot_product)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  491.25390625 MB\n",
      "Time taken:  3.200000047683716 ms\n",
      "CPU times: user 4.3 ms, sys: 0 ns, total: 4.3 ms\n",
      "Wall time: 3.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "# apply dot product of attention weights and value\n",
    "dot_product = torch.matmul(k.transpose(2, 3), v)\n",
    "attn_output = torch.matmul(q, dot_product)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7891716c-87bc-4d2b-bb83-b4ea194ca5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-19410.9375, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output[0][0][0][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51527ac0",
   "metadata": {},
   "source": [
    "## End-to-End Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fb651a-6b03-47be-8034-fc4bedcd842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 300000\n",
    "num_hidden = 256\n",
    "batch_size = 1\n",
    "attention_heads = 1\n",
    "h = torch.randn(batch_size, attention_heads, num_nodes, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dc26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "\n",
    "# apply linear layers to compute query, key, and value\n",
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b25759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  1172.87890625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65961e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  39070.4951171875 MB\n",
      "Time taken:  708.6981201171875 ms\n",
      "CPU times: user 699 ms, sys: 11.4 ms, total: 710 ms\n",
      "Wall time: 709 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "# compute dot product of query and key, and apply softmax\n",
    "attn_output = torch.matmul(torch.matmul(q, k.transpose(2, 3)), v)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  491.25390625 MB\n",
      "Time taken:  3.3904640674591064 ms\n",
      "CPU times: user 3.94 ms, sys: 0 ns, total: 3.94 ms\n",
      "Wall time: 3.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "# apply dot product of attention weights and value\n",
    "attn_output = torch.matmul(q, torch.matmul(k.transpose(2, 3), v))\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  1466.09765625 MB\n",
      "Time taken:  8.452095985412598 ms\n",
      "CPU times: user 7.33 ms, sys: 2.98 ms, total: 10.3 ms\n",
      "Wall time: 8.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    # apply dot product of attention weights and value\n",
    "    attn_output = torch.matmul(q, torch.matmul(k.transpose(2, 3), v))\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7891716c-87bc-4d2b-bb83-b4ea194ca5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-19410.9375, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output[0][0][0][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78376245",
   "metadata": {},
   "source": [
    "## Sparse Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fb651a-6b03-47be-8034-fc4bedcd842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c87d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100000\n",
    "edge_density = 10\n",
    "num_edges = num_nodes * edge_density\n",
    "num_hidden = 256\n",
    "batch_size = 1\n",
    "attention_heads = 1\n",
    "h = torch.randn(batch_size, attention_heads, num_nodes, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dc26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "\n",
    "# apply linear layers to compute query, key, and value\n",
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b25759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  393.00390625 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0977286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse version of the attention mechanism\n",
    "adjacency = torch.randint(0, num_nodes, (2, num_edges))\n",
    "\n",
    "# Convert to sparse torch tensor\n",
    "sp_adjacency = torch.sparse_coo_tensor(adjacency, torch.ones(num_edges), (num_nodes, num_nodes)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6032f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 37.25 GiB (GPU 0; 39.45 GiB total capacity; 413.00 MiB already allocated; 4.41 GiB free; 414.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dot_product \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mmm(sp_adjacency, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49msqueeze())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 37.25 GiB (GPU 0; 39.45 GiB total capacity; 413.00 MiB already allocated; 4.41 GiB free; 414.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "dot_product = torch.sparse.mm(sp_adjacency, k.transpose(2, 3).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60e53b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_adjacency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5500696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10000, 10000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd6032f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (10000) at non-singleton dimension 1.  Target sizes: [10000, 1].  Tensor sizes: [10000, 10000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mmm(sp_adjacency, q)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (10000) at non-singleton dimension 1.  Target sizes: [10000, 1].  Tensor sizes: [10000, 10000]"
     ]
    }
   ],
   "source": [
    "torch.sparse.mm(sp_adjacency, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory used:  3820.154296875 MB\n",
      "Time taken:  233.67987060546875 ms\n",
      "CPU times: user 236 ms, sys: 0 ns, total: 236 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    dot_product = torch.matmul(k.transpose(2, 3), v)\n",
    "    attn_output = torch.matmul(q, dot_product)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "print(\"GPU memory used: \", torch.cuda.max_memory_allocated()/1024**2, \"MB\")\n",
    "print(\"Time taken: \", start.elapsed_time(end), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn4na",
   "language": "python",
   "name": "gnn4na"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
