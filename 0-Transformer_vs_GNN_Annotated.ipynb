{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bb4a04e",
   "metadata": {},
   "source": [
    "# Attention Encoder: Two Equivalent Approaches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a86ec456",
   "metadata": {},
   "source": [
    "The following is a guide to the self-attention encoder update. If you feel most comfortable with Transformers, then start at the top and work down to the `Transformer Output` result. If you feel most comfortable with Graph Neural Networks, then start at the bottom and work up to the `GNN Output` result. Spoiler alert: They are equivalent mathematically. And indeed we expect that: The only difference is that the Transformer is a densely represented operation, the GNN is a sparesly represented operation. Check out the `2-PerformanceComparison` notebook for a comparison of the two approaches in terms of memory and timing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1df3a1-dd88-4fe0-a14c-827acca0182c",
   "metadata": {},
   "source": [
    "## Transformer Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dd605-41de-4a02-a87a-caefa628569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/gnn4na/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b5590-402f-4455-a07e-69cfcdd4406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 4\n",
    "num_hidden = 5\n",
    "batch_size = 1\n",
    "attention_heads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105115a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pytorch random seed\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92212b2c-d62e-4c88-adce-b4edfed0d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe6dfeb-94c3-46b4-8599-cbf8d5f92c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn(batch_size, attention_heads, num_nodes, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e85edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = torch.matmul(q, k.transpose(2, 3)) / math.sqrt(num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea41a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = softmax(dot_product)\n",
    "attn_output = torch.matmul(attn_weights, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef644973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Transformer output ----------------------\n",
      " tensor([[[[ 0.0539, -0.2314, -0.7193,  0.2311,  0.5558],\n",
      "          [ 0.0022,  0.2890, -0.1338, -0.1758,  0.5741],\n",
      "          [-0.1504,  0.6230,  0.3954, -0.5747,  0.5293],\n",
      "          [ 0.0375, -0.2709, -0.7365,  0.2375,  0.5486]]]], device='cuda:0',\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------- Transformer output ----------------------\\n\", attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef644973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0539, -0.2314, -0.7193,  0.2311,  0.5558],\n",
      "        [ 0.0022,  0.2890, -0.1338, -0.1758,  0.5741],\n",
      "        [-0.1504,  0.6230,  0.3954, -0.5747,  0.5293],\n",
      "        [ 0.0375, -0.2709, -0.7365,  0.2375,  0.5486]], device='cuda:0',\n",
      "       grad_fn=<ScatterAddBackward0>) \n",
      " ---------------------- GNN output -------------------------\n"
     ]
    }
   ],
   "source": [
    "print(attn_output, \"\\n ---------------------- GNN output -------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf5831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = scatter_add(attn_weights[:, None]*v[outgoing], incoming, dim=0, dim_size=h.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9858462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = utils.softmax(dot_product, incoming, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112daa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2910, -0.1490, -0.5712,  0.1110,  0.0089,  0.8476,  1.3841, -0.5947,\n",
       "        -0.5246,  0.4699,  2.5532, -1.0397,  0.2927, -0.4655, -0.7424,  0.1140],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da76016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming, outgoing = edges\n",
    "dot_product = (q[incoming]*k[outgoing]).sum(dim=-1) / math.sqrt(num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81417fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = linear_q(h)\n",
    "k = linear_k(h)\n",
    "v = linear_v(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe6dfeb-94c3-46b4-8599-cbf8d5f92c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.randn(num_nodes, num_hidden).to(\"cuda\")\n",
    "# h = h.squeeze()\n",
    "edges = torch.stack(torch.meshgrid(torch.arange(num_nodes), torch.arange(num_nodes))).reshape(2, -1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92212b2c-d62e-4c88-adce-b4edfed0d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_q = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_k = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "linear_v = nn.Linear(num_hidden, num_hidden).to(\"cuda\")\n",
    "softmax = nn.Softmax(dim=-1).to(\"cuda\")\n",
    "linear_out = nn.Linear(num_hidden, num_hidden).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105115a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pytorch random seed\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74b5590-402f-4455-a07e-69cfcdd4406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 4\n",
    "num_hidden = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b9e2b8-9916-4220-a434-93938b5a66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric import utils\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079393c-0b15-4de0-9536-cd4a3bd65739",
   "metadata": {},
   "source": [
    "## GNN Version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn4na",
   "language": "python",
   "name": "gnn4na"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) \n[GCC 10.4.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
